{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamKishoreSreedharan/food-lens/blob/main/TME_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLxFoQTYm68J"
      },
      "outputs": [],
      "source": [
        "# # !pip install mlflow databricks\n",
        "# !databricks configure --host https://community.cloud.databricks.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYtKrXrsm6jO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vspb6ZtyBDNP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import hashlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MjEfo7xe_lmj"
      },
      "outputs": [],
      "source": [
        "DIR = '/content/drive/MyDrive/project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woucbBO5VQoU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create organized subdirectories\n",
        "os.makedirs(os.path.join(DIR, \"images\"), exist_ok=True)          # For downloaded images\n",
        "os.makedirs(os.path.join(DIR, \"data\"), exist_ok=True)            # For CSVs\n",
        "os.makedirs(os.path.join(DIR, \"models/classifier\"), exist_ok=True)          # For autoencoder weights\n",
        "os.makedirs(os.path.join(DIR, \"models/cbir\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(DIR, \"latent_features\"), exist_ok=True) # For feature vectors\n",
        "SRC_FILENAME = 'data/recipe.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otwq7XKjVdCr"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(DIR + SRC_FILENAME, low_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z8Kj78gWAXw"
      },
      "outputs": [],
      "source": [
        "essential_cols = [\n",
        "    \"recipe_id\", \"title\", \"ingredients\", \"directions\",\n",
        "    \"prep_time\", \"cook_time\", \"total_time\", \"servings\",\n",
        "    \"image\", \"category\",'instructions_list','calories', 'carbohydrates_g', 'sugars_g', 'fat_g',\n",
        "    'saturated_fat_g', 'cholesterol_mg', 'protein_g', 'dietary_fiber_g', 'sodium_mg',  'url', \"rating\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLnFky9IevbZ"
      },
      "outputs": [],
      "source": [
        "nutrition_cols = [\n",
        "     'calories_from_fat',\n",
        "    'calcium_mg', 'iron_mg', 'magnesium_mg', 'potassium_mg',\n",
        "    'zinc_mg', 'phosphorus_mg', 'vitamin_a_iu_IU',\n",
        "    'niacin_equivalents_mg', 'vitamin_b6_mg', 'vitamin_c_mg',\n",
        "    'folate_mcg', 'thiamin_mg', 'riboflavin_mg',\n",
        "    'vitamin_e_iu_IU', 'vitamin_k_mcg', 'biotin_mcg',\n",
        "    'vitamin_b12_mcg', 'mono_fat_g', 'poly_fat_g',\n",
        "    'trans_fatty_acid_g', 'omega_3_fatty_acid_g',\n",
        "    'omega_6_fatty_acid_g',\n",
        "    'author', 'description', 'yields', 'rating_count',\n",
        "    'review_count'\n",
        "]\n",
        "\n",
        "df_clean = df.drop(columns=nutrition_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVeX1sr5MSFM"
      },
      "outputs": [],
      "source": [
        "# df_clean.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXUJU1H8SKBS"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "\n",
        "# Create a unique ID for each recipe\n",
        "df_clean[\"recipe_id\"] = df_clean[\"image\"].astype(str).apply(\n",
        "    lambda x: hashlib.md5(x.encode()).hexdigest()[:10]\n",
        ")\n",
        "df_clean = df_clean[df_clean['recipe_id'] != 'a3d2de7675']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-LZlPK9PHdL",
        "outputId": "2d513781-98d3-4227-cc0a-8a1f3d68f386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null counts after imputation:\n",
            "calories           0\n",
            "fat_g              0\n",
            "saturated_fat_g    0\n",
            "cholesterol_mg     0\n",
            "sugars_g           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "nutritional_cols = [\n",
        "    'calories', 'carbohydrates_g', 'sugars_g', 'fat_g',\n",
        "    'saturated_fat_g', 'cholesterol_mg', 'protein_g',\n",
        "    'dietary_fiber_g', 'sodium_mg'\n",
        "]\n",
        "\n",
        "# Calculate mean per category\n",
        "category_means = df_clean.groupby('category')[nutritional_cols].mean()\n",
        "\n",
        "# Impute missing values\n",
        "for col in nutritional_cols:\n",
        "    df_clean[col] = df_clean.apply(\n",
        "        lambda row: category_means.loc[row['category'], col] if pd.isna(row[col]) else row[col],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "# Verify no nulls remain in core metrics\n",
        "core_cols = ['calories', 'fat_g', 'saturated_fat_g', 'cholesterol_mg', 'sugars_g']\n",
        "print(\"Null counts after imputation:\")\n",
        "print(df_clean[core_cols].isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMLveybpM0ds"
      },
      "outputs": [],
      "source": [
        "# Classification function\n",
        "def classify_health(row):\n",
        "    # Check for nulls in core metrics\n",
        "    core = ['calories', 'fat_g', 'saturated_fat_g', 'cholesterol_mg', 'sugars_g']\n",
        "    if any(pd.isna(row[col]) for col in core):\n",
        "        return 'Unknown'\n",
        "\n",
        "    # Core thresholds\n",
        "    healthy_conditions = [\n",
        "        row['calories'] <= 200,\n",
        "        row['fat_g'] <= 10,\n",
        "        row['saturated_fat_g'] <= 3,\n",
        "        row['cholesterol_mg'] <= 30,\n",
        "        row['sugars_g'] <= 10\n",
        "    ]\n",
        "    unhealthy_conditions = [\n",
        "        row['calories'] > 400,\n",
        "        row['fat_g'] > 15,\n",
        "        row['saturated_fat_g'] > 6,\n",
        "        row['cholesterol_mg'] > 60,\n",
        "        row['sugars_g'] > 25\n",
        "    ]\n",
        "\n",
        "    # Optional boosts\n",
        "    protein_boost = row['protein_g'] >= 10 if not pd.isna(row['protein_g']) else False\n",
        "    fiber_boost = row['dietary_fiber_g'] >= 5 if not pd.isna(row['dietary_fiber_g']) else False\n",
        "    sodium_flag = row['sodium_mg'] > 600 if not pd.isna(row['sodium_mg']) else False\n",
        "\n",
        "    # Count conditions\n",
        "    healthy_count = sum(healthy_conditions)\n",
        "    unhealthy_count = sum(unhealthy_conditions)\n",
        "\n",
        "    # Classification\n",
        "    if healthy_count >= 4 or (healthy_count >= 3 and (protein_boost or fiber_boost)):\n",
        "        return 'Healthy'\n",
        "    elif unhealthy_count >= 2 or (unhealthy_count >= 1 and sodium_flag):\n",
        "        return 'Unhealthy'\n",
        "    return 'Moderate'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z25JqeJWQqfp"
      },
      "outputs": [],
      "source": [
        "# Scoring function\n",
        "def classify_diet(row):\n",
        "    cals = row['calories'] or 0\n",
        "    carbs = row['carbohydrates_g'] or 0\n",
        "    sugars = row['sugars_g'] or 0\n",
        "    fat = row['fat_g'] or 0\n",
        "    prot = row['protein_g'] or 0\n",
        "    fiber = row['dietary_fiber_g'] or 0\n",
        "    sodium = row['sodium_mg'] or 0\n",
        "\n",
        "    scores = {\n",
        "        'HCLF': 0, 'HPLC': 0, 'Balanced': 0, 'LCHF': 0, 'LCHFib': 0, 'Junk': 0\n",
        "    }\n",
        "\n",
        "    # Carbs\n",
        "    if carbs >= 40: scores['HCLF'] += 2; scores['HPLC'] -= 2; scores['LCHF'] -= 2\n",
        "    elif carbs <= 15: scores['HPLC'] += 2; scores['LCHF'] += 2; scores['HCLF'] -= 2\n",
        "    elif 20 <= carbs <= 40: scores['Balanced'] += 2\n",
        "\n",
        "    # Fat\n",
        "    if fat <= 10: scores['HCLF'] += 2; scores['LCHFib'] += 2; scores['Balanced'] += 1; scores['LCHF'] -= 2\n",
        "    elif fat >= 15: scores['LCHF'] += 2; scores['Junk'] += 1; scores['HCLF'] -= 2; scores['LCHFib'] -= 2\n",
        "    elif 5 <= fat <= 15: scores['Balanced'] += 1\n",
        "\n",
        "    # Protein\n",
        "    if prot >= 20: scores['HPLC'] += 2; scores['HCLF'] -= 1\n",
        "    elif 10 <= prot <= 20: scores['Balanced'] += 1; scores['LCHF'] += 1\n",
        "\n",
        "    # Calories\n",
        "    if cals <= 200: scores['LCHFib'] += 2; scores['Junk'] -= 2\n",
        "    elif cals > 300: scores['Junk'] += 2; scores['LCHFib'] -= 2\n",
        "\n",
        "    # Sugars\n",
        "    if sugars >= 25: scores['Junk'] += 2; scores['HCLF'] -= 1; scores['HPLC'] -= 1; scores['Balanced'] -= 1; scores['LCHF'] -= 1; scores['LCHFib'] -= 1\n",
        "    elif sugars <= 10: scores['LCHFib'] += 1; scores['Junk'] -= 1\n",
        "\n",
        "    # Fiber\n",
        "    if fiber >= 5: scores['HCLF'] += 1; scores['Balanced'] += 1; scores['LCHFib'] += 2; scores['Junk'] -= 1\n",
        "\n",
        "    # Sodium\n",
        "    if sodium > 600: scores['Balanced'] -= 1; scores['Junk'] += 1\n",
        "\n",
        "    # Classify\n",
        "    max_score = max(scores.values())\n",
        "    if max_score <= 0: return 'Other'\n",
        "    for diet, score in scores.items():\n",
        "        if score == max_score: return diet\n",
        "    return 'Other'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-G0cVlLM8ky"
      },
      "outputs": [],
      "source": [
        "df_clean['health_level'] = df_clean.apply(classify_health, axis=1)\n",
        "df_clean['diet'] = df_clean.apply(classify_diet, axis=1)\n",
        "# df.to_csv('/MyDrive/NewDataset/recipes_classified.csv', index=False)\n",
        "# print(df['HealthClassification'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "qRK80DBoNEIx",
        "outputId": "39ae5b53-f904-4f66-c814-d3b306127505"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diet\n",
              "LCHFib      7597\n",
              "Junk        7081\n",
              "Balanced    3502\n",
              "HPLC        2867\n",
              "LCHF        2442\n",
              "HCLF        1926\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diet</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LCHFib</th>\n",
              "      <td>7597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Junk</th>\n",
              "      <td>7081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced</th>\n",
              "      <td>3502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HPLC</th>\n",
              "      <td>2867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LCHF</th>\n",
              "      <td>2442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HCLF</th>\n",
              "      <td>1926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df_clean['diet'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rBUhQ8DqBaF"
      },
      "outputs": [],
      "source": [
        "df_clean.to_csv(os.path.join(DIR, \"data/recipes_classified.csv\"), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eu8VDEWqgyY"
      },
      "outputs": [],
      "source": [
        "df = df_clean.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "Dh7MTDZbSZP4",
        "outputId": "9f6388c4-383d-458c-e5cf-5112aaf14c59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        title  \\\n",
              "0  Simple Macaroni and Cheese   \n",
              "1    Gourmet Mushroom Risotto   \n",
              "2              Dessert Crepes   \n",
              "3                 Pork Steaks   \n",
              "4  Quick and Easy Pizza Crust   \n",
              "\n",
              "                                                 url              category  \\\n",
              "0  https://www.allrecipes.com/recipe/238691/simpl...             main-dish   \n",
              "1  https://www.allrecipes.com/recipe/85389/gourme...             main-dish   \n",
              "2  https://www.allrecipes.com/recipe/19037/desser...  breakfast-and-brunch   \n",
              "3  https://www.allrecipes.com/recipe/70463/pork-s...      meat-and-poultry   \n",
              "4  https://www.allrecipes.com/recipe/20171/quick-...                 bread   \n",
              "\n",
              "   rating                                        ingredients  \\\n",
              "0    4.42  1 (8 ounce) box elbow macaroni ; ¼ cup butter ...   \n",
              "1    4.80  6 cups chicken broth, divided ; 3 tablespoons ...   \n",
              "2    4.80  4  eggs, lightly beaten ; 1 ⅓ cups milk ; 2 ta...   \n",
              "3    4.57  ¼ cup butter ; ¼ cup soy sauce ; 1 bunch green...   \n",
              "4    4.70  1 (.25 ounce) package active dry yeast ; 1 tea...   \n",
              "\n",
              "                                          directions prep_time cook_time  \\\n",
              "0  Bring a large pot of lightly salted water to a...   10 mins   20 mins   \n",
              "1  In a saucepan, warm the broth over low heat. W...   20 mins   30 mins   \n",
              "2  In large bowl, whisk together eggs, milk, melt...   10 mins   10 mins   \n",
              "3  Melt butter in a skillet, and mix in the soy s...   15 mins   30 mins   \n",
              "4  Preheat oven to 450 degrees F (230 degrees C)....       NaN       NaN   \n",
              "\n",
              "  total_time  servings  ...  saturated_fat_g  cholesterol_mg  protein_g  \\\n",
              "0    30 mins         4  ...             20.9       99.600000       26.5   \n",
              "1    50 mins         6  ...              6.6       29.300000       11.3   \n",
              "2    20 mins         8  ...              3.4      111.100000        6.4   \n",
              "3    45 mins         6  ...             11.4      118.000000       26.5   \n",
              "4        NaN         8  ...              0.6       34.474707        4.8   \n",
              "\n",
              "   dietary_fiber_g  sodium_mg  \\\n",
              "0              2.1      777.0   \n",
              "1              2.7     1130.8   \n",
              "2              0.4      234.5   \n",
              "3              1.1      719.7   \n",
              "4              1.1      292.8   \n",
              "\n",
              "                                   instructions_list  \\\n",
              "0  ['Bring a large pot of lightly salted water to...   \n",
              "1  ['Warm broth in a saucepan over low heat.', 'M...   \n",
              "2  ['Whisk together eggs, milk, flour, melted but...   \n",
              "3  ['Melt butter in a skillet over medium heat; s...   \n",
              "4  ['Preheat oven to 450 degrees F (230 degrees C...   \n",
              "\n",
              "                                               image   recipe_id  \\\n",
              "0  https://www.allrecipes.com/thmb/GZrTl8DBwmRuor...  148ecaf409   \n",
              "1  https://www.allrecipes.com/thmb/xCk4IEjfAYBikO...  65fcb51062   \n",
              "2  https://www.allrecipes.com/thmb/VwULr05JFDluPI...  1191ef7390   \n",
              "3  https://www.allrecipes.com/thmb/mYkvln7o9pb35l...  d6b54b7cce   \n",
              "4  https://www.allrecipes.com/thmb/V3Llo-ottudIs_...  6bddaec59a   \n",
              "\n",
              "   health_level    diet  \n",
              "0     Unhealthy    Junk  \n",
              "1     Unhealthy    Junk  \n",
              "2      Moderate  LCHFib  \n",
              "3     Unhealthy    HPLC  \n",
              "4       Healthy  LCHFib  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6e30a42-1cb4-4a60-8576-78453bbc0dfb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>category</th>\n",
              "      <th>rating</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>directions</th>\n",
              "      <th>prep_time</th>\n",
              "      <th>cook_time</th>\n",
              "      <th>total_time</th>\n",
              "      <th>servings</th>\n",
              "      <th>...</th>\n",
              "      <th>saturated_fat_g</th>\n",
              "      <th>cholesterol_mg</th>\n",
              "      <th>protein_g</th>\n",
              "      <th>dietary_fiber_g</th>\n",
              "      <th>sodium_mg</th>\n",
              "      <th>instructions_list</th>\n",
              "      <th>image</th>\n",
              "      <th>recipe_id</th>\n",
              "      <th>health_level</th>\n",
              "      <th>diet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Simple Macaroni and Cheese</td>\n",
              "      <td>https://www.allrecipes.com/recipe/238691/simpl...</td>\n",
              "      <td>main-dish</td>\n",
              "      <td>4.42</td>\n",
              "      <td>1 (8 ounce) box elbow macaroni ; ¼ cup butter ...</td>\n",
              "      <td>Bring a large pot of lightly salted water to a...</td>\n",
              "      <td>10 mins</td>\n",
              "      <td>20 mins</td>\n",
              "      <td>30 mins</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>20.9</td>\n",
              "      <td>99.600000</td>\n",
              "      <td>26.5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>777.0</td>\n",
              "      <td>['Bring a large pot of lightly salted water to...</td>\n",
              "      <td>https://www.allrecipes.com/thmb/GZrTl8DBwmRuor...</td>\n",
              "      <td>148ecaf409</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>Junk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gourmet Mushroom Risotto</td>\n",
              "      <td>https://www.allrecipes.com/recipe/85389/gourme...</td>\n",
              "      <td>main-dish</td>\n",
              "      <td>4.80</td>\n",
              "      <td>6 cups chicken broth, divided ; 3 tablespoons ...</td>\n",
              "      <td>In a saucepan, warm the broth over low heat. W...</td>\n",
              "      <td>20 mins</td>\n",
              "      <td>30 mins</td>\n",
              "      <td>50 mins</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>6.6</td>\n",
              "      <td>29.300000</td>\n",
              "      <td>11.3</td>\n",
              "      <td>2.7</td>\n",
              "      <td>1130.8</td>\n",
              "      <td>['Warm broth in a saucepan over low heat.', 'M...</td>\n",
              "      <td>https://www.allrecipes.com/thmb/xCk4IEjfAYBikO...</td>\n",
              "      <td>65fcb51062</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>Junk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dessert Crepes</td>\n",
              "      <td>https://www.allrecipes.com/recipe/19037/desser...</td>\n",
              "      <td>breakfast-and-brunch</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4  eggs, lightly beaten ; 1 ⅓ cups milk ; 2 ta...</td>\n",
              "      <td>In large bowl, whisk together eggs, milk, melt...</td>\n",
              "      <td>10 mins</td>\n",
              "      <td>10 mins</td>\n",
              "      <td>20 mins</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>3.4</td>\n",
              "      <td>111.100000</td>\n",
              "      <td>6.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>234.5</td>\n",
              "      <td>['Whisk together eggs, milk, flour, melted but...</td>\n",
              "      <td>https://www.allrecipes.com/thmb/VwULr05JFDluPI...</td>\n",
              "      <td>1191ef7390</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>LCHFib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pork Steaks</td>\n",
              "      <td>https://www.allrecipes.com/recipe/70463/pork-s...</td>\n",
              "      <td>meat-and-poultry</td>\n",
              "      <td>4.57</td>\n",
              "      <td>¼ cup butter ; ¼ cup soy sauce ; 1 bunch green...</td>\n",
              "      <td>Melt butter in a skillet, and mix in the soy s...</td>\n",
              "      <td>15 mins</td>\n",
              "      <td>30 mins</td>\n",
              "      <td>45 mins</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>11.4</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>26.5</td>\n",
              "      <td>1.1</td>\n",
              "      <td>719.7</td>\n",
              "      <td>['Melt butter in a skillet over medium heat; s...</td>\n",
              "      <td>https://www.allrecipes.com/thmb/mYkvln7o9pb35l...</td>\n",
              "      <td>d6b54b7cce</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>HPLC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quick and Easy Pizza Crust</td>\n",
              "      <td>https://www.allrecipes.com/recipe/20171/quick-...</td>\n",
              "      <td>bread</td>\n",
              "      <td>4.70</td>\n",
              "      <td>1 (.25 ounce) package active dry yeast ; 1 tea...</td>\n",
              "      <td>Preheat oven to 450 degrees F (230 degrees C)....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>34.474707</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>292.8</td>\n",
              "      <td>['Preheat oven to 450 degrees F (230 degrees C...</td>\n",
              "      <td>https://www.allrecipes.com/thmb/V3Llo-ottudIs_...</td>\n",
              "      <td>6bddaec59a</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>LCHFib</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6e30a42-1cb4-4a60-8576-78453bbc0dfb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6e30a42-1cb4-4a60-8576-78453bbc0dfb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6e30a42-1cb4-4a60-8576-78453bbc0dfb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f19a25dc-9552-406c-aa00-d8f16152b764\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f19a25dc-9552-406c-aa00-d8f16152b764')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f19a25dc-9552-406c-aa00-d8f16152b764 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm-Ap7xzfTUc"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (512, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "752Pj9YyNKat"
      },
      "outputs": [],
      "source": [
        "remove = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljum0x6lfXq_"
      },
      "outputs": [],
      "source": [
        "# Download images with progress tracking\n",
        "def download_save_image(row):\n",
        "    try:\n",
        "        img_path = Path(DIR + 'images/' + f\"{row['recipe_id']}.jpg\")\n",
        "        # print(img_path)\n",
        "\n",
        "        if img_path.exists():  # Skip already downloaded\n",
        "            return True\n",
        "\n",
        "        response = requests.get(row['image'], timeout=15)\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        img = img.convert('RGB').resize(IMAGE_SIZE)\n",
        "        img.save(img_path, 'JPEG', quality=90)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Failed {row['recipe_id']}: {str(e)}\")\n",
        "        remove.append(row['recipe_id'])\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Constants\n",
        "DIR = \"/path/to/dataset/\"\n",
        "IMAGE_SIZE = (256, 256)  # Target size\n",
        "df = pd.read_csv(DIR + 'data/final.csv')\n",
        "remove = []  # List to store failed downloads\n",
        "IMAGE_DIR = Path(DIR) / \"images\"\n",
        "IMAGE_DIR.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\n",
        "\n",
        "# Function to download and save an image\n",
        "def download_save_image(row):\n",
        "    try:\n",
        "        img_path = IMAGE_DIR / f\"{row['recipe_id']}.jpg\"\n",
        "        if img_path.exists():  # Skip if already downloaded\n",
        "            return row['recipe_id'], True\n",
        "\n",
        "        response = requests.get(row['image'], timeout=15)\n",
        "        if response.status_code == 200:\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            img = img.convert('RGB').resize(IMAGE_SIZE)\n",
        "            img.save(img_path, 'JPEG', quality=90)\n",
        "            return row['recipe_id'], True\n",
        "        else:\n",
        "            raise Exception(f\"HTTP {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        return row['recipe_id'], False  # Return failed recipe ID\n",
        "\n",
        "# Run concurrent downloading\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
        "    futures = {executor.submit(download_save_image, row): row['recipe_id'] for _, row in df.iterrows()}\n",
        "\n",
        "    # Track progress\n",
        "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Downloading Images\"):\n",
        "        recipe_id, success = future.result()\n",
        "        if not success:\n",
        "            remove.append(recipe_id)\n",
        "\n",
        "# Save failed download list\n",
        "if remove:\n",
        "    pd.DataFrame(remove, columns=['recipe_id']).to_csv(DIR + \"failed_downloads.csv\", index=False)\n",
        "    print(f\"Failed downloads saved: {len(remove)} images\")\n"
      ],
      "metadata": {
        "id": "p0vzC9b-3zvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFxy8to0ibML"
      },
      "outputs": [],
      "source": [
        "# 7bc84360b0, 8a0a4ffe66, 15d879b56e, 6b1a599fcf, 25351ef3d6, 4090db5c8c, 8376f5af72, d637804a15, 59d80de8ad, a1e64da808, 4090db5c8c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmvEEGqqfe-i",
        "outputId": "c717ddd9-2d4f-42de-f9c6-359e773b26f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 296/25415 [00:14<11:15, 37.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed 7bc84360b0: cannot identify image file <_io.BytesIO object at 0x7d8a935e7b00>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 2637/25415 [00:15<00:19, 1195.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed 8a0a4ffe66: cannot identify image file <_io.BytesIO object at 0x7d8a935e74c0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 5032/25415 [05:35<1:04:10,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed 6b1a599fcf: cannot identify image file <_io.BytesIO object at 0x7d8a93706e30>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 8330/25415 [19:15<1:11:08,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed 25351ef3d6: cannot identify image file <_io.BytesIO object at 0x7d8a93704ef0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 10402/25415 [27:32<1:04:52,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed 4090db5c8c: Invalid URL 'NaNname': No scheme supplied. Perhaps you meant https://NaNname?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 15302/25415 [47:29<38:42,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed d637804a15: cannot identify image file <_io.BytesIO object at 0x7d8a93706980>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 17575/25415 [56:43<27:09,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed 59d80de8ad: cannot identify image file <_io.BytesIO object at 0x7d8a935e5da0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 17818/25415 [57:35<28:13,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed a1e64da808: cannot identify image file <_io.BytesIO object at 0x7d8a93707ab0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 19171/25415 [1:02:36<13:59,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed 4090db5c8c: Invalid URL 'NaNname': No scheme supplied. Perhaps you meant https://NaNname?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25415/25415 [1:29:51<00:00,  4.71it/s]\n"
          ]
        }
      ],
      "source": [
        "# Batch processing with status tracking\n",
        "success_mask = []\n",
        "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    success_mask.append(download_save_image(row))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i5ebL3pNyuN",
        "outputId": "bf36cd04-ea9a-4955-d26c-fbbe6b545f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['7bc84360b0', '8a0a4ffe66', '6b1a599fcf', '25351ef3d6', '4090db5c8c', 'd637804a15', '59d80de8ad', 'a1e64da808', '4090db5c8c']\n"
          ]
        }
      ],
      "source": [
        "print(remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIlUSoiaftc3",
        "outputId": "51d3cff4-ebec-4e41-faad-c2ac35038de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25406\n"
          ]
        }
      ],
      "source": [
        "# Create clean dataset\n",
        "df_clean_downloaded = df[success_mask].reset_index(drop=True)\n",
        "df_clean_downloaded = df_clean_downloaded[~df_clean_downloaded['recipe_id'].isin(remove)]\n",
        "print(len(df_clean_downloaded))\n",
        "df_clean_downloaded.to_csv(DIR + '/data/final.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISqnj1eAODUA",
        "outputId": "35b01200-b4b5-4fb4-fd2c-98176a27a779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded 25406/25415 images\n"
          ]
        }
      ],
      "source": [
        "print(f\"Successfully downloaded {len(df_clean_downloaded)}/{len(df)} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B57VSkOzmSCe"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(os.path.join(DIR, \"images_aug\"), exist_ok=True)"
      ],
      "metadata": {
        "id": "HYM8gPbIvWQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEPcycFdT2By"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssiGoMPkT51m"
      },
      "outputs": [],
      "source": [
        "# Image augmentation pipeline\n",
        "augment = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ToPILImage()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9xJTt9bueCG",
        "outputId": "ba7e6a03-acaf-458d-d8c5-2b94cb6f6637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LCHFib: 7597 (Target: 4000)\n",
            "Junk: 7081 (Target: 4000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting Balanced: 100%|██████████| 498/498 [00:16<00:00, 29.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced: 4000 (Target: 4000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting HPLC: 100%|██████████| 1133/1133 [00:42<00:00, 26.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HPLC: 4000 (Target: 4000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting LCHF: 100%|██████████| 1558/1558 [01:12<00:00, 21.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LCHF: 4000 (Target: 4000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting HCLF: 100%|██████████| 2074/2074 [01:11<00:00, 29.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HCLF: 4000 (Target: 4000)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import concurrent.futures\n",
        "\n",
        "IMAGE_DIR = Path(DIR) / 'images/'\n",
        "IMG_OUT_DIR = Path(DIR) / 'images_aug/'\n",
        "# Image augmentation pipeline\n",
        "augment = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ToPILImage()\n",
        "])\n",
        "\n",
        "# Target size per class (match LCHFib)\n",
        "TARGET_SIZE = 4000\n",
        "classes = ['LCHFib', 'Junk', 'Balanced', 'HPLC', 'LCHF', 'HCLF']\n",
        "augmented_data = []\n",
        "\n",
        "\n",
        "def augment_image(row, i):\n",
        "    \"\"\"Function to augment a single image.\"\"\"\n",
        "    orig_img_path = IMAGE_DIR / f\"{row['recipe_id']}.jpg\"\n",
        "    new_recipe_id = f\"{row['recipe_id']}_aug{i}\"\n",
        "    new_img_path = IMG_OUT_DIR / f\"{new_recipe_id}.jpg\"\n",
        "\n",
        "    try:\n",
        "        if new_img_path.exists():\n",
        "            # If augmented image already exists, reuse it\n",
        "            new_row = row.copy()\n",
        "            new_row['recipe_id'] = new_recipe_id\n",
        "            new_row['image'] = f\"{new_recipe_id}.jpg\"\n",
        "            return pd.DataFrame([new_row])\n",
        "\n",
        "        if orig_img_path.exists():\n",
        "            # Load and augment original image\n",
        "            img = Image.open(orig_img_path).convert('RGB')\n",
        "            aug_img = augment(img)\n",
        "            aug_img.save(new_img_path)\n",
        "\n",
        "            new_row = row.copy()\n",
        "            new_row['recipe_id'] = new_recipe_id\n",
        "            new_row['image'] = f\"{new_recipe_id}.jpg\"\n",
        "            return pd.DataFrame([new_row])\n",
        "        else:\n",
        "            print(f\"Original image not found: {orig_img_path}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {orig_img_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Process each class with outer tqdm\n",
        "for diet in classes:\n",
        "    class_df = df[df['diet'] == diet]\n",
        "    current_count = len(class_df)\n",
        "\n",
        "    if current_count >= TARGET_SIZE:\n",
        "        # No augmentation needed, keep as is\n",
        "        augmented_data.append(class_df)\n",
        "    else:\n",
        "        # Add original rows\n",
        "        augmented_data.append(class_df)\n",
        "        extra_needed = TARGET_SIZE - current_count\n",
        "\n",
        "        # Parallel processing for image augmentation\n",
        "        with concurrent.futures.ProcessPoolExecutor(max_workers=8) as executor:  # Adjust workers based on CPU cores\n",
        "            futures = [executor.submit(augment_image, class_df.sample(1, random_state=i).iloc[0], i)\n",
        "                       for i in range(extra_needed)]\n",
        "\n",
        "            for future in tqdm(concurrent.futures.as_completed(futures), total=extra_needed, desc=f\"Augmenting {diet}\"):\n",
        "                result = future.result()\n",
        "                if result is not None:\n",
        "                    augmented_data.append(result)\n",
        "\n",
        "    # Verify class size\n",
        "    class_size = sum(len(df[df['diet'] == diet]) for df in augmented_data if diet in df['diet'].values)\n",
        "    print(f\"{diet}: {class_size} (Target: {TARGET_SIZE})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine and save\n",
        "augmented_df = pd.concat(augmented_data).reset_index(drop=True)\n",
        "augmented_df.to_csv(DIR + 'data/recipes_augmented_balanced.csv', index=False)\n",
        "\n",
        "print(\"Final distribution:\")\n",
        "print(augmented_df['diet'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk5ZXxAn3IOM",
        "outputId": "f5ea6ff6-edf1-467d-eac9-f24156e06574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final distribution:\n",
            "diet\n",
            "LCHFib      7597\n",
            "Junk        7081\n",
            "Balanced    4000\n",
            "HPLC        4000\n",
            "LCHF        4000\n",
            "HCLF        4000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(augmented_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0OFohf438at",
        "outputId": "cb94c807-4a47-4435-fd79-fd192be47317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30678"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DytJIXXDmXOD"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "6m_iZ-lpC8Wa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iZqU5-fMC9h2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KuaWtKY8C8JL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y_0IOSBtk9h6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# class CBIRCAutoEncoder(nn.Module):\n",
        "#     def __init__(self, latent_dim=128, num_classes=6):\n",
        "#         super(CBIRCAutoEncoder, self).__init__()\n",
        "#         # Encoder: 256x256 -> 128-D\n",
        "#         self.encoder = nn.Sequential(\n",
        "#             nn.Conv2d(3, 32, 4, stride=2, padding=1),  # [3, 256, 256] -> [32, 128, 128]\n",
        "#             nn.ReLU(),\n",
        "#             nn.Conv2d(32, 64, 4, stride=2, padding=1),  # [64, 64, 64]\n",
        "#             nn.ReLU(),\n",
        "#             nn.Conv2d(64, 128, 4, stride=2, padding=1),  # [128, 32, 32]\n",
        "#             nn.ReLU(),\n",
        "#             nn.Conv2d(128, 256, 4, stride=2, padding=1),  # [256, 16, 16]\n",
        "#             nn.ReLU(),\n",
        "#             nn.Flatten(),\n",
        "#             nn.Linear(256 * 16 * 16, latent_dim)  # [128]\n",
        "#         )\n",
        "#         # Decoder: 128-D -> 256x256 (for training only)\n",
        "#         self.decoder = nn.Sequential(\n",
        "#             nn.Linear(latent_dim, 256 * 16 * 16),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Unflatten(1, (256, 16, 16)),\n",
        "#             nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),\n",
        "#             nn.Sigmoid()\n",
        "#         )\n",
        "#         # Classifier: 128-D -> 6 classes\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Linear(latent_dim, 64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(64, num_classes)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         latent = self.encoder(x)\n",
        "#         recon = self.decoder(latent)\n",
        "#         class_logits = self.classifier(latent)\n",
        "#         return recon, class_logits\n",
        "\n",
        "#     def get_latent(self, x):\n",
        "#         return self.encoder(x)  # For CBIR\n",
        "\n",
        "#     def classify(self, x):\n",
        "#         latent = self.encoder(x)\n",
        "#         return self.classifier(latent)  # For diet_level"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find if any accelerator is presented, if yes switch device to use CUDA or else use CPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0-M0i4r6s9G",
        "outputId": "9af349ff-92bc-403b-86fc-6549faebf58e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CBIRCAutoEncoder(nn.Module):\n",
        "    def __init__(self, latent_dim=128, num_classes=6):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, stride=1, padding=1),  # [64, 256, 256]\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2),  # [64, 128, 128]\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),  # [128, 64, 64]\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(128, 128, 3, stride=1),  # [128, 62, 62]\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2),  # [128, 31, 31]\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),  # [256, 16, 16]\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "        self.fc_latent = nn.Linear(256 * 16 * 16, latent_dim)  # [65536, 128]\n",
        "        self.fc_to_decoder = nn.Linear(latent_dim, 256 * 16 * 16)  # [128, 65536]\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 256, 3, stride=1, padding=1),  # [256, 16, 16]\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 256, 3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2),  # [128, 33, 33]\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1),  # [64, 66, 66]\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1),  # [32, 132, 132]\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1),  # [32, 264, 264]\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, 3, 3, stride=2, padding=0, output_padding=1),  # [3, 529, 529]\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)  # [64, 65536]\n",
        "        latent = self.fc_latent(x)  # [64, 128]\n",
        "        decoder_input = self.fc_to_decoder(latent).view(-1, 256, 16, 16)\n",
        "        recon = self.decoder(decoder_input)  # [64, 3, 529, 529]\n",
        "        recon = recon[:, :, :256, :256]  # Crop to [64, 3, 256, 256]\n",
        "        logits = self.classifier(latent)  # [64, 6]\n",
        "        return recon, logits\n"
      ],
      "metadata": {
        "id": "ppyd7qg44qbB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QcD9_ah45Dzx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.makedirs(\"images\")"
      ],
      "metadata": {
        "id": "G1q-4Q2I4u3k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r \"/content/drive/MyDrive/project/images\" \"/content/images\""
      ],
      "metadata": {
        "id": "1G_5O-delP-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5XI37uc9lAj0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "class RecipeDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.image_dir = Path(image_dir)  # Faster with Pathlib\n",
        "        self.transform = transform\n",
        "        self.label_map = {lbl: idx for idx, lbl in enumerate(sorted(df['diet'].unique()))}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        if \"_aug\" in row['recipe_id']:\n",
        "          img_path = self.image_dir / \"images_aug\" / f\"{row['recipe_id']}.jpg\"\n",
        "        else:\n",
        "          img_path = self.image_dir / f\"{row['recipe_id']}.jpg\"\n",
        "\n",
        "        # Handle missing files to avoid crashes\n",
        "        if not img_path.exists():\n",
        "            print(f\"Warning: Missing image {img_path}\")\n",
        "            return torch.zeros(3, 256, 256), 0  # Return empty tensor if missing\n",
        "\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label = self.label_map[row['diet']]\n",
        "        return img, label\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/project/data/recipes_augmented_balanced.csv\")\n",
        "\n",
        "# Define transformations including normalization\n",
        "transform = T.Compose([\n",
        "    T.Resize((256, 256)),  # Resize to 256x256\n",
        "    T.ToTensor(),  # Convert image to tensor\n",
        "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize with mean and std\n",
        "])\n",
        "\n",
        "dataset = RecipeDataset(df, \"/content/drive/MyDrive/project/images\", transform)\n",
        "# Split dataset into 80% training and 20% testing\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "test_size = len(dataset) - train_size  # 20% for testing\n",
        "\n",
        "# Use random_split to create training and testing datasets\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoader for training and testing sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=5, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=5, pin_memory=True)"
      ],
      "metadata": {
        "id": "k_uTR_Vp-R38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c60a332-cca0-4155-ebe0-fa6c402da530"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bhBSTpGg-TXc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0sZ4FqGlYWC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CBIRCAutoEncoder(latent_dim=128, num_classes=6).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "recon_loss_fn = nn.MSELoss()\n",
        "class_loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rModz0-qOOPi",
        "outputId": "cf7f7f8b-d695-43c2-ca79-3515b5e782d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CBIRCAutoEncoder(\n",
            "  (encoder): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "  )\n",
            "  (fc_latent): Linear(in_features=65536, out_features=128, bias=True)\n",
            "  (fc_to_decoder): Linear(in_features=128, out_features=65536, bias=True)\n",
            "  (decoder): Sequential(\n",
            "    (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2), output_padding=(1, 1))\n",
            "    (13): Sigmoid()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=6, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otj_oD4AAVgY",
        "outputId": "092181b3-5128-4fdf-cfae-3104a26af43f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   7%|▋         | 25/384 [05:31<34:55,  5.84s/it, class_loss=1.7333, loss=1.1964, recon_loss=0.3297]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/25351ef3d6.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  12%|█▏        | 45/384 [08:50<33:47,  5.98s/it, class_loss=1.7508, loss=1.2118, recon_loss=0.3364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/7bc84360b0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  17%|█▋        | 65/384 [11:44<31:19,  5.89s/it, class_loss=1.6607, loss=1.1590, recon_loss=0.3287]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/a1e64da808.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:  17%|█▋        | 65/384 [12:00<31:19,  5.89s/it, class_loss=1.6607, loss=1.1590, recon_loss=0.3287]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/d637804a15.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  48%|████▊     | 185/384 [30:30<19:47,  5.97s/it, class_loss=1.6683, loss=1.1366, recon_loss=0.3025]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/4090db5c8c.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  69%|██████▉   | 265/384 [42:40<11:29,  5.79s/it, class_loss=1.8009, loss=1.4138, recon_loss=0.5134]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/8a0a4ffe66.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  84%|████████▍ | 324/384 [51:37<07:17,  7.28s/it, class_loss=1.7538, loss=1.1927, recon_loss=0.3158]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/59d80de8ad.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  85%|████████▌ | 328/384 [52:17<07:19,  7.84s/it, class_loss=1.7015, loss=1.1628, recon_loss=0.3121]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/6b1a599fcf.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  93%|█████████▎| 359/384 [56:58<03:01,  7.27s/it, class_loss=1.8115, loss=1.2446, recon_loss=0.3388]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/4090db5c8c.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 384/384 [1:00:49<00:00,  9.50s/it, class_loss=1.7454, loss=1.2140, recon_loss=0.3413]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Total Loss: 1.2124, Recon Loss: 0.3376, Class Loss: 1.7496\n",
            "Saved best model to /content/drive/MyDrive/project/models/1_1.2124.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  12%|█▏        | 45/384 [00:07<00:44,  7.63it/s, class_loss=1.7659, loss=1.2063, recon_loss=0.3233]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/4090db5c8c.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  14%|█▍        | 55/384 [00:09<00:42,  7.80it/s, class_loss=1.7489, loss=1.2084, recon_loss=0.3340]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/6b1a599fcf.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  17%|█▋        | 66/384 [00:11<01:00,  5.28it/s, class_loss=1.7292, loss=1.2097, recon_loss=0.3451]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/a1e64da808.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  27%|██▋       | 102/384 [00:17<00:46,  6.05it/s, class_loss=1.8161, loss=1.2354, recon_loss=0.3274]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/59d80de8ad.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  30%|██▉       | 114/384 [00:18<00:39,  6.88it/s, class_loss=1.7027, loss=1.1818, recon_loss=0.3305]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/d637804a15.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  30%|███       | 117/384 [00:19<00:49,  5.42it/s, class_loss=1.7822, loss=1.2196, recon_loss=0.3285]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/4090db5c8c.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  32%|███▏      | 121/384 [00:19<00:39,  6.58it/s, class_loss=1.6896, loss=1.1582, recon_loss=0.3134]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/7bc84360b0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  34%|███▎      | 129/384 [00:21<00:38,  6.65it/s, class_loss=1.8275, loss=1.2290, recon_loss=0.3153]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/25351ef3d6.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  62%|██████▏   | 237/384 [00:38<00:26,  5.64it/s, class_loss=1.7261, loss=1.2003, recon_loss=0.3372]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/8a0a4ffe66.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 384/384 [01:00<00:00,  6.33it/s, class_loss=1.7154, loss=1.1470, recon_loss=0.2893]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Total Loss: 1.2049, Recon Loss: 0.3312, Class Loss: 1.7476\n",
            "Saved best model to /content/drive/MyDrive/project/models/2_1.2049.pth\n",
            "Saved final model to /content/drive/MyDrive/project/models/final.pth\n"
          ]
        }
      ],
      "source": [
        "EPOCH = 2\n",
        "MODELS_DIR = Path(DIR) / 'models'\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "best_loss = float('inf')\n",
        "\n",
        "# Initialize a list to store loss history for plotting\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    epoch_loss = 0.0\n",
        "    recon_loss_epoch = 0.0\n",
        "    class_loss_epoch = 0.0\n",
        "\n",
        "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}\") as pbar:\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            recon, logits = model(images)\n",
        "\n",
        "            # Compute losses\n",
        "            recon_loss = recon_loss_fn(recon, images)\n",
        "            class_loss = class_loss_fn(logits, labels)\n",
        "\n",
        "            # Combine losses\n",
        "            loss = recon_loss + 0.5 * class_loss\n",
        "\n",
        "            # Backpropagation and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate losses\n",
        "            epoch_loss += loss.item() * images.size(0)\n",
        "            recon_loss_epoch += recon_loss.item() * images.size(0)\n",
        "            class_loss_epoch += class_loss.item() * images.size(0)\n",
        "\n",
        "            # Update progress bar with detailed loss information\n",
        "            pbar.set_postfix(\n",
        "                loss=f\"{loss.item():.4f}\",\n",
        "                recon_loss=f\"{recon_loss.item():.4f}\",\n",
        "                class_loss=f\"{class_loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "    # Average losses for the epoch\n",
        "    epoch_loss /= len(train_loader.dataset)\n",
        "    recon_loss_epoch /= len(train_loader.dataset)\n",
        "    class_loss_epoch /= len(train_loader.dataset)\n",
        "\n",
        "    # Store losses in history for plotting\n",
        "    loss_history.append({\n",
        "        'epoch': epoch + 1,\n",
        "        'total_loss': epoch_loss,\n",
        "        'recon_loss': recon_loss_epoch,\n",
        "        'class_loss': class_loss_epoch\n",
        "    })\n",
        "\n",
        "    # Print epoch-wise loss\n",
        "    print(f\"Epoch {epoch+1}, Total Loss: {epoch_loss:.4f}, Recon Loss: {recon_loss_epoch:.4f}, Class Loss: {class_loss_epoch:.4f}\")\n",
        "\n",
        "    # Save best model based on total loss\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        save_path = MODELS_DIR / f\"{epoch+1}_{epoch_loss:.4f}.pth\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Saved best model to {save_path}\")\n",
        "\n",
        "# Save the final model\n",
        "final_path = MODELS_DIR / 'final.pth'\n",
        "torch.save(model.state_dict(), final_path)\n",
        "print(f\"Saved final model to {final_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwmrTNM5K-7M",
        "outputId": "e864d791-275d-44ed-f752-5a84f00ed5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total files and folders: 24750\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = DIR + \"images/\"\n",
        "file_count = len(os.listdir(folder_path))\n",
        "print(f\"Total files and folders: {file_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh9wq7yTLgeN",
        "outputId": "a178e59c-0bff-4554-8b96-9c7df650d3e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total missing images: 10\n",
            "Sample missing images: ['7bc84360b0', '8376f5af72', 'd637804a15', '4090db5c8c', '6b1a599fcf']\n",
            "Total extra images: 0\n",
            "Sample extra images: []\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Define paths\n",
        "folder_path = Path(DIR) / \"images\"\n",
        "csv_path = Path(DIR) / \"data/final.csv\"\n",
        "\n",
        "# Load recipe IDs from DataFrame and clean them\n",
        "df = pd.read_csv(csv_path, dtype={\"recipe_id\": str})  # Ensure recipe_id is string\n",
        "df[\"recipe_id\"] = df[\"recipe_id\"].str.strip()  # Remove spaces\n",
        "valid_ids = set(df[\"recipe_id\"])\n",
        "\n",
        "# Get all image filenames (without extensions)\n",
        "image_filenames = {img.stem.strip() for img in folder_path.glob(\"*.jpg\")}\n",
        "\n",
        "# Find missing images\n",
        "missing_images = valid_ids - image_filenames\n",
        "extra_images = image_filenames - valid_ids\n",
        "\n",
        "print(f\"Total missing images: {len(missing_images)}\")\n",
        "print(f\"Sample missing images: {list(missing_images)[:5]}\")\n",
        "print(f\"Total extra images: {len(extra_images)}\")\n",
        "print(f\"Sample extra images: {list(extra_images)[:5]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuhO9MRBMB7M",
        "outputId": "d2a61efc-828c-42c9-db1e-bd3b5d6fd049"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25415"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWuQX_ZsXHed"
      },
      "outputs": [],
      "source": [
        "# {'$schema': 'http://json-schema.org/schema#',\n",
        "#  'type': 'array',\n",
        "#  'items': {'type': 'object',\n",
        "#   'properties': {'id': {'type': 'string'},\n",
        "#    'images': {'type': 'array',\n",
        "#     'items': {'type': 'object',\n",
        "#      'properties': {'id': {'type': 'string'}, 'url': {'type': 'string'}},\n",
        "#      'required': ['id', 'url']}}},\n",
        "#   'required': ['id', 'images']}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADYlJrpxWEbn"
      },
      "outputs": [],
      "source": [
        "# {'$schema': 'http://json-schema.org/schema#',\n",
        "#  'type': 'array',\n",
        "#  'items': {'type': 'object',\n",
        "#   'properties': {'ingredients': {'type': 'array',\n",
        "#     'items': {'type': 'object',\n",
        "#      'properties': {'text': {'type': 'string'}},\n",
        "#      'required': ['text']}},\n",
        "#    'url': {'type': 'string'},\n",
        "#    'partition': {'type': 'string'},\n",
        "#    'title': {'type': 'string'},\n",
        "#    'id': {'type': 'string'},\n",
        "#    'instructions': {'type': 'array',\n",
        "#     'items': {'type': 'object',\n",
        "#      'properties': {'text': {'type': 'string'}},\n",
        "#      'required': ['text']}}},\n",
        "#   'required': ['id',\n",
        "#    'ingredients',\n",
        "#    'instructions',\n",
        "#    'partition',\n",
        "#    'title',\n",
        "#    'url']}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IZ1Faod6GKpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f668d8-c701-470e-ba92-a225f4dfdd88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CBIRCAutoEncoder(\n",
              "  (encoder): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "  )\n",
              "  (fc_latent): Linear(in_features=65536, out_features=128, bias=True)\n",
              "  (fc_to_decoder): Linear(in_features=128, out_features=65536, bias=True)\n",
              "  (decoder): Sequential(\n",
              "    (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2), output_padding=(1, 1))\n",
              "    (13): Sigmoid()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=6, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Define the device (use GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the model (ensure it matches the architecture used during training)\n",
        "model = CBIRCAutoEncoder()  # Replace with your actual model class\n",
        "model.load_state_dict(torch.load(DIR + \"models/final.pth\", map_location=device))  # Load weights\n",
        "model.to(device)\n",
        "model.eval()  # Set model to evaluation mode\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming test_loader is defined (e.g., batch_size=64, same as train_loader)\n",
        "# Verify test_loader setup\n",
        "images, labels = next(iter(test_loader))\n",
        "print(f\"Test batch shape: {images.shape}, Labels shape: {labels.shape}\")  # [64, 3, 256, 256], [64]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2RfRc47LIVA",
        "outputId": "1d05f90b-118a-4d5a-b2d9-6f9cfbe451c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test batch shape: torch.Size([64, 3, 256, 256]), Labels shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # No gradients needed for inference\n",
        "    for images, labels in tqdm(test_loader, desc=\"Inference\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        _, logits = model(images)  # Ignore recon, we want logits\n",
        "        preds = torch.argmax(logits, dim=1)  # Predicted class indices\n",
        "\n",
        "        # Accumulate for accuracy\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Store for detailed analysis\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = correct / total * 100\n",
        "print(f\"Test Accuracy: {accuracy:.2f}% ({correct}/{total})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S63TpoTIf5c",
        "outputId": "71ba38fe-2749-4783-8319-7372b160885b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference:  16%|█▌        | 15/96 [01:41<10:04,  7.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing image /content/drive/MyDrive/project/images/6b1a599fcf.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference:  74%|███████▍  | 71/96 [10:56<03:27,  8.28s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Class names (adjust if your labels differ)\n",
        "class_names = ['LCHFib', 'Junk', 'Balanced', 'HPLC', 'LCHF', 'HCLF']\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Optional: Visualize confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vOVI4XUCI-gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "el-6URRRK2oj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1B6gYpA9q8w-iqRmzCuloaAZ7cpx69iuu",
      "authorship_tag": "ABX9TyNbP28f7cQ2v9tQAJ+qYIr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}